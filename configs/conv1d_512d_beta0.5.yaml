# Conv1D VAE with 512D Latent + Lower Beta
# Combined fix for posterior collapse from run_002 analysis:
# 1. Larger latent space (512D instead of 256D) - 8:1 compression
# 2. Lower max_beta (0.5 instead of 1.0) - less KL pressure
#
# Expected improvements:
# - KL loss should stay ~50-100 (not collapse to 0.01)
# - Recon loss should improve below 0.8 (vs 3.2 in run_002)
# - More latent dimensions should remain active (not just 10-20)
# - Latent space diversity should be maintained

experiment_name: "conv1d_512d_beta0.5"

model:
  name: "conv1d_512d_beta0.5"
  latent_dim: 512  # ← DOUBLED from 256 (reduces compression 16:1 → 8:1)
  encoder_filters: [32, 64, 128]
  decoder_filters: [64, 32, 16]
  dropout_rates: [0.1, 0.15, 0.2]

training:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  beta_warmup_epochs: 50
  max_beta: 0.5  # ← HALVED from 1.0 (less KL regularization pressure)
  mixed_precision: true

data:
  train_dir: "data/delaunay/npz/train"
  dev_dir: "data/delaunay/npz/dev"
  test_dir: "data/delaunay/npz/test"
  stats_path: "data/normalization_stats.npz"
  shuffle_buffer: 1000

callbacks:
  checkpoint_every: 10
  early_stopping_patience: 15
  reduce_lr_patience: 5
  reduce_lr_factor: 0.5
  min_lr: 0.000001

output_dir: "outputs/conv1d_512d_beta0.5"
seed: 42
