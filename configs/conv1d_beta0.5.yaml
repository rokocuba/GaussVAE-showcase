# Conv1D VAE with Lower Beta
# Alternative fix for posterior collapse: less KL regularization pressure
# Allows model to focus more on reconstruction quality
#
# NOTE: max_beta is not yet configurable in TrainingConfig
# To use this, modify conv1d_trainer.py line 166:
#   BetaAnnealingCallback(max_beta=0.5, ...)  # instead of 1.0

experiment_name: "conv1d_beta0.5"

model:
  name: "conv1d"
  latent_dim: 256
  encoder_filters: [32, 64, 128]
  decoder_filters: [64, 32, 16]
  dropout_rates: [0.1, 0.15, 0.2]

training:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  beta_warmup_epochs: 50  # Still warmup over 50 epochs, max_beta hardcoded to 1.0
  mixed_precision: true

data:
  train_dir: "data/delaunay/npz/train"
  dev_dir: "data/delaunay/npz/dev"
  test_dir: "data/delaunay/npz/test"
  stats_path: "data/normalization_stats.npz"
  shuffle_buffer: 1000

callbacks:
  checkpoint_every: 10
  early_stopping_patience: 15
  reduce_lr_patience: 5
  reduce_lr_factor: 0.5
  min_lr: 0.000001

output_dir: "outputs/conv1d_beta0.5"
seed: 42
